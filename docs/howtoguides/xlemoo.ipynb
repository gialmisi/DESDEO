{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use XLEMOO: Explainable Learnable Multiobjective Optimization\n",
    "\n",
    "XLEMOO is a hybrid evolutionary-ML approach that combines evolutionary algorithms\n",
    "(Darwinian mode) with interpretable machine learning (Learning mode) to find\n",
    "near-Pareto optimal solutions while providing **explainability** about what makes\n",
    "solutions good.\n",
    "\n",
    "The core idea is that by training interpretable ML models on the population history,\n",
    "we can extract human-readable rules describing what characterizes high-performing\n",
    "solutions. These rules can then be used to instantiate new candidate solutions\n",
    "directly.\n",
    "\n",
    "**Reference:**\n",
    "Misitano, G. (2024). Towards Explainable Multiobjective Optimization: XLEMOO.\n",
    "*ACM Trans. Evol. Learn. Optim.*, 4(1). https://doi.org/10.1145/3626104\n",
    "\n",
    "**Prerequisites:** Before proceeding, make sure you are familiar with:\n",
    "\n",
    "- [How evolutionary algorithms are structured in DESDEO](../../explanation/templates_and_pub_sub)\n",
    "- [How to configure evolutionary algorithms with the Pydantic interface](../ea_options)\n",
    "- [How multiobjective optimization problems are defined](../../explanation/problem_format.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How XLEMOO works\n",
    "\n",
    "XLEMOO alternates between two modes:\n",
    "\n",
    "**Darwinian mode** uses a standard evolutionary algorithm (e.g., RVEA or NSGA-III)\n",
    "with crossover, mutation, and selection operators. This is identical to running\n",
    "a conventional EA.\n",
    "\n",
    "**Learning mode** replaces the standard evolutionary operators with an ML-based\n",
    "pipeline:\n",
    "\n",
    "1. Read population history from the archive.\n",
    "2. Rank solutions by a scalar fitness indicator and split into a\n",
    "   **H-group** (high-performing) and **L-group** (low-performing).\n",
    "3. Train an interpretable ML classifier to distinguish H from L.\n",
    "4. Extract rules from the classifier and instantiate new candidate\n",
    "   solutions based on those rules.\n",
    "5. Evaluate the candidates using the shared evaluator.\n",
    "6. Select the best solutions using the same Darwinian selector.\n",
    "\n",
    "In DESDEO, these responsibilities are split across the instantiator operator,\n",
    "the shared evaluator, and the Darwinian selector:\n",
    "\n",
    "```\n",
    "Darwinian mode (N iterations):\n",
    "  offspring       = crossover(population)\n",
    "  offspring       = mutate(offspring)\n",
    "  offspring_eval  = evaluator.evaluate(offspring)\n",
    "  population      = selection(parents, offspring)\n",
    "\n",
    "Learning mode (M iterations):\n",
    "  candidates      = instantiator(population)        # ML rules -> variables\n",
    "  candidates_eval = evaluator.evaluate(candidates)   # shared evaluator\n",
    "  population      = selection(parents, candidates)   # same selector\n",
    "```\n",
    "\n",
    "Because the evaluation step goes through the shared `EMOEvaluator`,\n",
    "all components (terminator, archives, etc.) are correctly notified about\n",
    "the function evaluations performed during learning mode. Using the same\n",
    "selector (e.g., RVEA) for both modes preserves population diversity\n",
    "across the Darwinian-Learning mode boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running XLEMOO with ASF-guided learning\n",
    "\n",
    "The simplest way to run XLEMOO is with the pre-configured\n",
    "`xlemoo_nsga2_options()`, which pairs NSGA-II as the Darwinian selector\n",
    "with a Decision Tree classifier for learning mode.\n",
    "\n",
    "In this example we use the **Achievement Scalarizing Function (ASF)** as\n",
    "the fitness indicator for the H/L group ranking. ASF incorporates a\n",
    "reference point provided by the decision maker, guiding the learning mode\n",
    "to focus on solutions near that preferred region. The reference point\n",
    "$z = (0.5, 0.5, 0.5)$ sits near the center of the DTLZ2 Pareto front\n",
    "(the unit sphere in the positive octant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from desdeo.emo.options.algorithms import emo_constructor, xlemoo_nsga2_options\n",
    "from desdeo.emo.options.xlemoo_selection import XLEMOOSelectorOptions\n",
    "from desdeo.problem.testproblems import dtlz2\n",
    "\n",
    "# Define a 3-objective, 6-variable DTLZ2 problem\n",
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "# Get pre-configured XLEMOO-NSGA2 options\n",
    "options = xlemoo_nsga2_options()\n",
    "\n",
    "# Use ASF with a reference point for H/L group ranking\n",
    "reference_point = [0.5, 0.5, 0.5]\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=reference_point,\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "# Build and run the solver\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "print(f\"Solutions found: {len(results.optimal_outputs)}\")\n",
    "print(results.optimal_outputs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the Pareto front approximation. For DTLZ2 with 3 objectives,\n",
    "the true Pareto front lies on the unit sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    results.optimal_outputs,\n",
    "    x=\"f_1\",\n",
    "    y=\"f_2\",\n",
    "    z=\"f_3\",\n",
    "    title=\"XLEMOO-NSGA2 on DTLZ2 (3 objectives)\",\n",
    ")\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show(renderer=\"notebook\", include_plotlyjs=\"cdn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify proximity to unit sphere\n",
    "obj_values = results.optimal_outputs[[\"f_1\", \"f_2\", \"f_3\"]].to_numpy()\n",
    "norms = np.sqrt(np.sum(obj_values**2, axis=1))\n",
    "print(f\"Median distance to unit sphere: {np.median(norms):.4f}\")\n",
    "print(f\"Min: {norms.min():.4f}, Max: {norms.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the default configuration\n",
    "\n",
    "Let's inspect the options returned by `xlemoo_nsga2_options()` to understand\n",
    "the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.pretty import pprint\n",
    "\n",
    "options = xlemoo_nsga2_options()\n",
    "pprint(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key XLEMOO-specific settings live in `options.template.learning_selection`\n",
    "(`XLEMOOSelectorOptions`), and in the template-level cycle parameters:\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|---|---|---|\n",
    "| `darwin_iterations_per_cycle` | 10 | EA generations per cycle before switching to learning mode |\n",
    "| `learning_iterations_per_cycle` | 1 | Learning mode iterations per cycle |\n",
    "| `ml_model_type` | `DecisionTree` | Interpretable ML classifier to use |\n",
    "| `h_split` | 0.1 | Fraction of best solutions for the H-group |\n",
    "| `l_split` | 0.1 | Fraction of worst solutions for the L-group |\n",
    "| `instantiation_factor` | 2.0 | How many candidates to generate (multiplier of population size) |\n",
    "| `fitness_indicator` | `naive_sum` | How to compute scalar fitness for ranking (`naive_sum`, `asf`, `hypervolume`) |\n",
    "| `asf_reference_point` | None | Reference point for ASF (required when `fitness_indicator=\"asf\"`) |\n",
    "| `asf_weights` | None | Weights for ASF (defaults to equal weights if None) |\n",
    "| `generation_lookback` | 0 | How many recent generations to use (0 = all history) |\n",
    "| `ancestral_recall` | 0 | Earliest generations to always include |\n",
    "| `unique_only` | False | Deduplicate solutions before training |\n",
    "\n",
    "Using `asf` with a decision-maker-supplied reference point is the recommended\n",
    "configuration, as it directs the learning mode toward the preferred region of\n",
    "the Pareto front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the ML model\n",
    "\n",
    "XLEMOO supports several interpretable ML classifiers. The available types are:\n",
    "\n",
    "- `DecisionTree` (scikit-learn `DecisionTreeClassifier`)\n",
    "- `SkopeRules` (from [imodels](https://github.com/csinva/imodels))\n",
    "- `Slipper` (from imodels)\n",
    "- `BoostedRules` (from imodels)\n",
    "\n",
    "You can change the ML model and pass additional keyword arguments to its\n",
    "constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "options = xlemoo_nsga2_options()\n",
    "# Reduce generations for a quicker run\n",
    "options.template.termination.max_generations = 50\n",
    "\n",
    "# Switch to SkopeRules with custom parameters and ASF fitness\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    ml_model_type=\"SkopeRules\",\n",
    "    ml_model_kwargs={\n",
    "        \"precision_min\": 0.1,\n",
    "        \"n_estimators\": 30,\n",
    "        \"max_features\": None,\n",
    "        \"max_depth\": None,\n",
    "    },\n",
    "    h_split=0.2,\n",
    "    l_split=0.2,\n",
    "    instantiation_factor=5.0,\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.5, 0.5, 0.5],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "print(f\"Solutions found: {len(results.optimal_outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a fitness indicator\n",
    "\n",
    "The fitness indicator determines how solutions are ranked into H-group\n",
    "(good) and L-group (bad) during the learning mode. Three options are\n",
    "available:\n",
    "\n",
    "**`asf`** (Achievement Scalarizing Function): Uses a reference point and\n",
    "weights to rank solutions by proximity to the decision maker's preference.\n",
    "This is the recommended indicator, as it focuses the ML model on the\n",
    "region of interest.\n",
    "\n",
    "$$\\text{ASF}(f) = \\max_i \\bigl[ w_i (f_i - z_i) \\bigr] + \\rho \\sum_i w_i (f_i - z_i)$$\n",
    "\n",
    "**`naive_sum`**: Sums all minimized target values. Simple and fast,\n",
    "but does not incorporate preference information.\n",
    "\n",
    "**`hypervolume`**: Uses individual hypervolume contribution. More expensive\n",
    "to compute, but provides a distribution-aware ranking.\n",
    "\n",
    "Below we compare the effect of changing the reference point. A reference\n",
    "point closer to the origin focuses the H-group on solutions in that corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "# Run with a reference point biased toward f_1\n",
    "options = xlemoo_nsga2_options()\n",
    "options.template.termination.max_generations = 50\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.2, 0.8, 0.8],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "obj_values = results.optimal_outputs[[\"f_1\", \"f_2\", \"f_3\"]].to_numpy()\n",
    "print(f\"Solutions found: {len(results.optimal_outputs)}\")\n",
    "print(\"Reference point: [0.2, 0.8, 0.8] (biased toward low f_1)\")\n",
    "print(f\"Objective ranges: {obj_values.min(axis=0).round(3)} to {obj_values.max(axis=0).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the Darwinian/Learning mode cycle\n",
    "\n",
    "The `darwin_iterations_per_cycle` and `learning_iterations_per_cycle`\n",
    "parameters control how many iterations are spent in each mode before switching.\n",
    "\n",
    "For example, with 100 total generations, 10 Darwinian iterations per cycle,\n",
    "and 1 learning iteration per cycle, the algorithm will run approximately\n",
    "9 full cycles (each consisting of 10 EA generations + 1 learning step =\n",
    "11 generations counted by the terminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "options = xlemoo_nsga2_options()\n",
    "options.template.termination.max_generations = 60\n",
    "\n",
    "# Use ASF for H/L ranking\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.5, 0.5, 0.5],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "# More frequent learning: 5 Darwinian + 2 learning per cycle\n",
    "options.template.darwin_iterations_per_cycle = 5\n",
    "options.template.learning_iterations_per_cycle = 2\n",
    "\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "print(f\"Solutions found: {len(results.optimal_outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation lookback and ancestral recall\n",
    "\n",
    "By default, the learning mode uses the entire population history to train\n",
    "the ML model (`generation_lookback=0`). You can limit this to only recent\n",
    "generations, which may be useful for problems where the landscape changes\n",
    "or when you want the ML model to focus on recently discovered good solutions.\n",
    "\n",
    "- `generation_lookback`: Only use the last N generations (0 = use all).\n",
    "- `ancestral_recall`: Always include the first N generations alongside\n",
    "  the lookback window. Useful for preserving early exploration diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "options = xlemoo_nsga2_options()\n",
    "options.template.termination.max_generations = 60\n",
    "\n",
    "# Use ASF for H/L ranking\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.5, 0.5, 0.5],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "# Only look at the last 20 generations, but always include the first 3\n",
    "options.template.learning_selection.generation_lookback = 20\n",
    "options.template.learning_selection.ancestral_recall = 3\n",
    "\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "print(f\"Solutions found: {len(results.optimal_outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the learning archive\n",
    "\n",
    "The `ConstructorExtras` object returned by `emo_constructor` includes a\n",
    "`learning_archive` that stores the full history of all evaluated solutions\n",
    "(from both Darwinian and Learning modes). This can be used for post-hoc\n",
    "analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "options = xlemoo_nsga2_options()\n",
    "options.template.termination.max_generations = 50\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.5, 0.5, 0.5],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "# The learning archive contains all evaluated solutions with generation numbers\n",
    "archive_df = extras.learning_archive.solutions\n",
    "print(f\"Total solutions in learning archive: {len(archive_df)}\")\n",
    "print(f\"Generations covered: {archive_df['generation'].min()} to {archive_df['generation'].max()}\")\n",
    "print(f\"\\nArchive columns: {archive_df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and interpreting rules\n",
    "\n",
    "One of the key features of XLEMOO is the ability to extract human-readable\n",
    "rules from the ML model. The `desdeo.explanations.rule_interpreters` module\n",
    "provides utilities for this.\n",
    "\n",
    "The following example trains a Decision Tree on the final archive data and\n",
    "extracts rules describing what characterizes the best solutions. We use\n",
    "the same ASF indicator with a reference point to rank solutions into\n",
    "H-group and L-group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from desdeo.explanations.rule_interpreters import find_all_paths\n",
    "\n",
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "\n",
    "options = xlemoo_nsga2_options()\n",
    "options.template.termination.max_generations = 50\n",
    "options.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.5, 0.5, 0.5],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "solver, extras = emo_constructor(emo_options=options, problem=problem)\n",
    "results = solver()\n",
    "\n",
    "# Extract variable and target data from the archive\n",
    "archive_df = extras.learning_archive.solutions\n",
    "var_cols = [f\"x_{i}\" for i in range(1, 7)]\n",
    "target_cols = [f\"f_{i}_min\" for i in range(1, 4)]\n",
    "\n",
    "X = archive_df[var_cols].to_numpy()\n",
    "targets = archive_df[target_cols].to_numpy()\n",
    "\n",
    "# Compute ASF fitness (same as the learning mode uses) and split into H/L groups\n",
    "z = np.array([0.5, 0.5, 0.5])\n",
    "w = np.array([1.0, 1.0, 1.0])\n",
    "rho = 1e-6\n",
    "weighted = (targets - z) * w\n",
    "fitness = np.max(weighted, axis=1) + rho * np.sum(weighted, axis=1)\n",
    "\n",
    "sorted_idx = np.argsort(fitness)\n",
    "n = len(sorted_idx)\n",
    "h_count = max(1, int(0.1 * n))\n",
    "l_count = max(1, int(0.1 * n))\n",
    "\n",
    "h_idx = sorted_idx[:h_count]\n",
    "l_idx = sorted_idx[-l_count:]\n",
    "\n",
    "# Train a Decision Tree\n",
    "X_train = np.vstack((X[h_idx], X[l_idx]))\n",
    "y_train = np.hstack(\n",
    "    (\n",
    "        np.ones(h_count, dtype=int),\n",
    "        -np.ones(l_count, dtype=int),\n",
    "    )\n",
    ")\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Extract paths from the tree\n",
    "paths = find_all_paths(tree)\n",
    "\n",
    "# Print rules for paths classified as \"good\" (class 1)\n",
    "print(f\"Total paths in tree: {len(paths)}\")\n",
    "print(f\"Paths classified as H-group (good): {sum(1 for p in paths if p['classification'] == 1)}\")\n",
    "print()\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    if path[\"classification\"] == 1:\n",
    "        print(f\"--- Path {i} (samples: {path['samples']}, impurity: {path['impurity']:.3f}) ---\")\n",
    "        for rule in path[\"rules\"]:\n",
    "            feature_idx, op, threshold = rule[0], rule[1], rule[2]\n",
    "            var_name = f\"x_{feature_idx + 1}\"\n",
    "            op_str = \"<=\" if op == \"lte\" else \">\"\n",
    "            print(f\"  {var_name} {op_str} {float(threshold):.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules above describe decision variable conditions that characterize\n",
    "high-performing solutions. For DTLZ2, the true Pareto-optimal solutions have\n",
    "$x_i = 0.5$ for $i \\geq 3$ (the distance variables), so we expect the rules\n",
    "to reflect conditions near $x_i \\approx 0.5$ for those variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing XLEMOO with standard NSGA-II\n",
    "\n",
    "Let's compare the performance of XLEMOO-NSGA2 against standard NSGA-II on the\n",
    "same problem and budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desdeo.emo.options.algorithms import nsga2_options\n",
    "\n",
    "problem = dtlz2(n_objectives=3, n_variables=6)\n",
    "max_gens = 100\n",
    "\n",
    "# Standard NSGA-II\n",
    "nsga2_opts = nsga2_options()\n",
    "nsga2_opts.template.termination.max_generations = max_gens\n",
    "nsga2_solver, _ = emo_constructor(emo_options=nsga2_opts, problem=problem)\n",
    "nsga2_results = nsga2_solver()\n",
    "\n",
    "# XLEMOO-NSGA2 with ASF\n",
    "xlemoo_opts = xlemoo_nsga2_options()\n",
    "xlemoo_opts.template.termination.max_generations = max_gens\n",
    "xlemoo_opts.template.learning_selection = XLEMOOSelectorOptions(\n",
    "    fitness_indicator=\"asf\",\n",
    "    asf_reference_point=[0.5, 0.5, 0.5],\n",
    "    asf_weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "xlemoo_solver, _ = emo_constructor(emo_options=xlemoo_opts, problem=problem)\n",
    "xlemoo_results = xlemoo_solver()\n",
    "\n",
    "# Compare distance to unit sphere\n",
    "nsga2_obj = nsga2_results.optimal_outputs[[\"f_1\", \"f_2\", \"f_3\"]].to_numpy()\n",
    "xlemoo_obj = xlemoo_results.optimal_outputs[[\"f_1\", \"f_2\", \"f_3\"]].to_numpy()\n",
    "\n",
    "nsga2_norms = np.sqrt(np.sum(nsga2_obj**2, axis=1))\n",
    "xlemoo_norms = np.sqrt(np.sum(xlemoo_obj**2, axis=1))\n",
    "\n",
    "print(f\"{'':>20} {'NSGA-II':>10} {'XLEMOO-NSGA2':>14}\")\n",
    "print(f\"{'Solutions found':>20} {len(nsga2_obj):>10} {len(xlemoo_obj):>14}\")\n",
    "print(f\"{'Median norm':>20} {np.median(nsga2_norms):>10.4f} {np.median(xlemoo_norms):>14.4f}\")\n",
    "print(f\"{'Mean norm':>20} {np.mean(nsga2_norms):>10.4f} {np.mean(xlemoo_norms):>14.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=nsga2_obj[:, 0],\n",
    "        y=nsga2_obj[:, 1],\n",
    "        z=nsga2_obj[:, 2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=3, color=\"blue\", opacity=0.6),\n",
    "        name=\"NSGA-II\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=xlemoo_obj[:, 0],\n",
    "        y=xlemoo_obj[:, 1],\n",
    "        z=xlemoo_obj[:, 2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=3, color=\"red\", opacity=0.6),\n",
    "        name=\"XLEMOO-NSGA2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"NSGA-II vs XLEMOO-NSGA2 on DTLZ2\",\n",
    "    scene=dict(xaxis_title=\"f_1\", yaxis_title=\"f_2\", zaxis_title=\"f_3\"),\n",
    ")\n",
    "fig.show(renderer=\"notebook\", include_plotlyjs=\"cdn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "XLEMOO extends standard evolutionary algorithms with interpretable machine\n",
    "learning to provide both optimization and explainability. Key takeaways:\n",
    "\n",
    "- Use `xlemoo_nsga2_options()` for a ready-to-run configuration.\n",
    "- The `learning_selection` field in `Template3Options` controls all ML\n",
    "  parameters.\n",
    "- Use the **ASF** fitness indicator with a decision-maker-supplied reference\n",
    "  point to focus the learning mode on the preferred region of the Pareto\n",
    "  front.\n",
    "- Tune `darwin_iterations_per_cycle` and `learning_iterations_per_cycle`\n",
    "  to balance exploration vs. exploitation.\n",
    "- Use the `learning_archive` and rule extraction utilities for post-hoc\n",
    "  analysis and explainability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
